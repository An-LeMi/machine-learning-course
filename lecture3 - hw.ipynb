{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, Y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only classify class 1 vs class 2\n",
    "idx = (Y > 0)\n",
    "X = X[idx, :]\n",
    "Y = Y[idx]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "Remember: normalization is done per feature, not all at once. Also, remember that Y is [1, 2] instead of [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Don't forget the bias!\n",
    "for i in range (0,4):\n",
    "    X[:, i] = (X[:,i] - np.mean(X[:,i].T)) / np.std(X[:, i].T)\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), axis = 1)\n",
    "Y = Y - 1  # class 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  1.11900931,  0.99068792, -0.25077906, -0.65303909],\n",
       "        [ 1.        ,  0.20924564,  0.99068792, -0.49425387, -0.41643072],\n",
       "        [ 1.        ,  0.96738203,  0.68864892, -0.00730424, -0.41643072],\n",
       "        [ 1.        , -1.15539985, -1.72766308, -1.10294091, -0.88964745],\n",
       "        [ 1.        ,  0.36087292, -0.21746808, -0.37251647, -0.41643072],\n",
       "        [ 1.        , -0.8521453 , -0.21746808, -0.49425387, -0.88964745],\n",
       "        [ 1.        ,  0.05761837,  1.29272692, -0.25077906, -0.17982236],\n",
       "        [ 1.        , -2.06516352, -1.42562408, -1.95510276, -1.59947255],\n",
       "        [ 1.        ,  0.5125002 ,  0.08457092, -0.37251647, -0.88964745],\n",
       "        [ 1.        , -1.61028169, -0.51950708, -1.22467832, -0.65303909],\n",
       "        [ 1.        , -1.91353624, -2.63378009, -1.71162795, -1.59947255],\n",
       "        [ 1.        , -0.54889074,  0.38660992, -0.8594661 , -0.41643072],\n",
       "        [ 1.        , -0.39726347, -2.02970209, -1.10294091, -1.59947255],\n",
       "        [ 1.        , -0.24563619,  0.08457092, -0.25077906, -0.65303909],\n",
       "        [ 1.        , -1.00377258,  0.08457092, -1.58989054, -0.88964745],\n",
       "        [ 1.        ,  0.66412748,  0.68864892, -0.61599128, -0.65303909],\n",
       "        [ 1.        , -1.00377258,  0.38660992, -0.49425387, -0.41643072],\n",
       "        [ 1.        , -0.70051802, -0.51950708, -0.9812035 , -1.59947255],\n",
       "        [ 1.        , -0.09400891, -2.02970209, -0.49425387, -0.41643072],\n",
       "        [ 1.        , -1.00377258, -1.12358508, -1.22467832, -1.36286418],\n",
       "        [ 1.        , -0.54889074,  0.99068792, -0.12904165,  0.29339437],\n",
       "        [ 1.        , -0.24563619, -0.21746808, -1.10294091, -0.88964745],\n",
       "        [ 1.        ,  0.05761837, -1.12358508, -0.00730424, -0.41643072],\n",
       "        [ 1.        , -0.24563619, -0.21746808, -0.25077906, -1.12625582],\n",
       "        [ 1.        ,  0.20924564,  0.08457092, -0.73772869, -0.88964745],\n",
       "        [ 1.        ,  0.5125002 ,  0.38660992, -0.61599128, -0.65303909],\n",
       "        [ 1.        ,  0.81575475, -0.21746808, -0.12904165, -0.65303909],\n",
       "        [ 1.        ,  0.66412748,  0.38660992,  0.11443316,  0.05678601],\n",
       "        [ 1.        , -0.39726347,  0.08457092, -0.49425387, -0.41643072],\n",
       "        [ 1.        , -0.8521453 , -0.82154608, -1.71162795, -1.59947255],\n",
       "        [ 1.        , -1.15539985, -1.42562408, -1.34641572, -1.36286418],\n",
       "        [ 1.        , -1.15539985, -1.42562408, -1.46815313, -1.59947255],\n",
       "        [ 1.        , -0.70051802, -0.51950708, -1.22467832, -1.12625582],\n",
       "        [ 1.        , -0.39726347, -0.51950708,  0.23617057, -0.17982236],\n",
       "        [ 1.        , -1.30702713,  0.38660992, -0.49425387, -0.41643072],\n",
       "        [ 1.        , -0.39726347,  1.59476592, -0.49425387, -0.17982236],\n",
       "        [ 1.        ,  0.66412748,  0.68864892, -0.25077906, -0.41643072],\n",
       "        [ 1.        ,  0.05761837, -1.72766308, -0.61599128, -0.88964745],\n",
       "        [ 1.        , -1.00377258,  0.38660992, -0.9812035 , -0.88964745],\n",
       "        [ 1.        , -1.15539985, -1.12358508, -1.10294091, -0.88964745],\n",
       "        [ 1.        , -1.15539985, -0.82154608, -0.61599128, -1.12625582],\n",
       "        [ 1.        , -0.24563619,  0.38660992, -0.37251647, -0.65303909],\n",
       "        [ 1.        , -0.70051802, -0.82154608, -1.10294091, -1.12625582],\n",
       "        [ 1.        , -1.91353624, -1.72766308, -1.95510276, -1.59947255],\n",
       "        [ 1.        , -1.00377258, -0.51950708, -0.8594661 , -0.88964745],\n",
       "        [ 1.        , -0.8521453 ,  0.38660992, -0.8594661 , -1.12625582],\n",
       "        [ 1.        , -0.8521453 ,  0.08457092, -0.8594661 , -0.88964745],\n",
       "        [ 1.        , -0.09400891,  0.08457092, -0.73772869, -0.88964745],\n",
       "        [ 1.        , -1.76190896, -1.12358508, -2.32031498, -1.36286418],\n",
       "        [ 1.        , -0.8521453 , -0.21746808, -0.9812035 , -0.88964745],\n",
       "        [ 1.        ,  0.05761837,  1.29272692,  1.33180724,  1.94965293],\n",
       "        [ 1.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
       "        [ 1.        ,  1.27063658,  0.38660992,  1.21006983,  1.00321947],\n",
       "        [ 1.        ,  0.05761837,  0.08457092,  0.84485761,  0.29339437],\n",
       "        [ 1.        ,  0.36087292,  0.38660992,  1.08833242,  1.23982783],\n",
       "        [ 1.        ,  2.02877297,  0.38660992,  2.06223168,  1.00321947],\n",
       "        [ 1.        , -2.06516352, -1.12358508, -0.49425387,  0.05678601],\n",
       "        [ 1.        ,  1.57389114,  0.08457092,  1.69701946,  0.29339437],\n",
       "        [ 1.        ,  0.66412748, -1.12358508,  1.08833242,  0.29339437],\n",
       "        [ 1.        ,  1.42226386,  2.19884393,  1.45354464,  1.94965293],\n",
       "        [ 1.        ,  0.36087292,  0.99068792,  0.23617057,  0.7666111 ],\n",
       "        [ 1.        ,  0.20924564, -0.51950708,  0.47964538,  0.53000274],\n",
       "        [ 1.        ,  0.81575475,  0.38660992,  0.7231202 ,  1.00321947],\n",
       "        [ 1.        , -0.8521453 , -1.12358508,  0.11443316,  0.7666111 ],\n",
       "        [ 1.        , -0.70051802, -0.21746808,  0.23617057,  1.71304456],\n",
       "        [ 1.        ,  0.20924564,  0.99068792,  0.47964538,  1.4764362 ],\n",
       "        [ 1.        ,  0.36087292,  0.38660992,  0.7231202 ,  0.29339437],\n",
       "        [ 1.        ,  2.18040025,  2.80292193,  2.18396909,  1.23982783],\n",
       "        [ 1.        ,  2.18040025, -0.82154608,  2.4274439 ,  1.4764362 ],\n",
       "        [ 1.        , -0.39726347, -2.02970209,  0.11443316, -0.41643072],\n",
       "        [ 1.        ,  0.96738203,  0.99068792,  0.96659501,  1.4764362 ],\n",
       "        [ 1.        , -1.00377258, -0.21746808, -0.00730424,  0.7666111 ],\n",
       "        [ 1.        ,  2.18040025, -0.21746808,  2.18396909,  0.7666111 ],\n",
       "        [ 1.        ,  0.05761837, -0.51950708, -0.00730424,  0.29339437],\n",
       "        [ 1.        ,  0.66412748,  1.29272692,  0.96659501,  1.00321947],\n",
       "        [ 1.        ,  1.42226386,  0.99068792,  1.33180724,  0.29339437],\n",
       "        [ 1.        , -0.09400891, -0.21746808, -0.12904165,  0.29339437],\n",
       "        [ 1.        , -0.24563619,  0.38660992, -0.00730424,  0.29339437],\n",
       "        [ 1.        ,  0.20924564, -0.21746808,  0.84485761,  1.00321947],\n",
       "        [ 1.        ,  1.42226386,  0.38660992,  1.08833242, -0.17982236],\n",
       "        [ 1.        ,  1.72551842, -0.21746808,  1.45354464,  0.53000274],\n",
       "        [ 1.        ,  2.4836548 ,  2.80292193,  1.81875686,  0.7666111 ],\n",
       "        [ 1.        ,  0.20924564, -0.21746808,  0.84485761,  1.23982783],\n",
       "        [ 1.        ,  0.05761837, -0.21746808,  0.23617057, -0.41643072],\n",
       "        [ 1.        , -0.24563619, -0.82154608,  0.84485761, -0.65303909],\n",
       "        [ 1.        ,  2.18040025,  0.38660992,  1.45354464,  1.4764362 ],\n",
       "        [ 1.        ,  0.05761837,  1.59476592,  0.84485761,  1.71304456],\n",
       "        [ 1.        ,  0.20924564,  0.68864892,  0.7231202 ,  0.29339437],\n",
       "        [ 1.        , -0.39726347,  0.38660992, -0.12904165,  0.29339437],\n",
       "        [ 1.        ,  0.96738203,  0.68864892,  0.60138279,  1.00321947],\n",
       "        [ 1.        ,  0.66412748,  0.68864892,  0.84485761,  1.71304456],\n",
       "        [ 1.        ,  0.96738203,  0.68864892,  0.23617057,  1.4764362 ],\n",
       "        [ 1.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
       "        [ 1.        ,  0.81575475,  0.99068792,  1.21006983,  1.4764362 ],\n",
       "        [ 1.        ,  0.66412748,  1.29272692,  0.96659501,  1.94965293],\n",
       "        [ 1.        ,  0.66412748,  0.38660992,  0.35790798,  1.4764362 ],\n",
       "        [ 1.        ,  0.05761837, -1.12358508,  0.11443316,  0.53000274],\n",
       "        [ 1.        ,  0.36087292,  0.38660992,  0.35790798,  0.7666111 ],\n",
       "        [ 1.        , -0.09400891,  1.59476592,  0.60138279,  1.4764362 ],\n",
       "        [ 1.        , -0.54889074,  0.38660992,  0.23617057,  0.29339437]]),\n",
       " array([62.33231539, 10.14978227,  0.9271052 , 21.42746216, 24.79431046]))"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classification model\n",
    "Create parameters here. Initialize with zeros. In case you forgot: $Y = \\sigma(X\\Theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.zeros(X.shape[1])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 1e-2\n",
    "# epochs\n",
    "epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, Y, weight):\n",
    "    z = sigmoid(X @ weight)\n",
    "    return -np.sum(Y * np.log(z) + (1 - Y) *  np.log(1 - z)) / (Y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12047504, -0.44156746, -0.89309501,  2.965364  ,  3.3427994 ])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sgd(X, Y, weight, alpha, epoch):\n",
    "    for i in range(10000):\n",
    "        gd = (X.T @ (sigmoid(X @ weight) - Y)) / (Y.size)\n",
    "        weight -= alpha * gd\n",
    "    return weight\n",
    "weight = sgd(X, Y, weight, alpha, epoch)\n",
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(X, Y, weight):\n",
    "    '''\n",
    "    Evaluate the model, represented by `weight`, with data (X, Y).\n",
    "    \n",
    "    Input:\n",
    "        X:      data features\n",
    "        Y:      data labels\n",
    "        weight: model weights\n",
    "    Ouput:\n",
    "        Model accuracy on input data.\n",
    "    '''\n",
    "    \n",
    "    # implement your code here\n",
    "    y_predict = []\n",
    "    for i in sigmoid(X @ weight):\n",
    "        if i > 0.5:\n",
    "            y_predict.append(1)\n",
    "        else: y_predict.append(0)\n",
    "    return float(np.sum(Y == y_predict) / (Y.size)) \n",
    "y_predict = accuracy(X,Y,weight)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 1e-2\n",
    "# epochs\n",
    "epoch = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to double check\n",
    "assert np.allclose(weight, np.array([0.12047504, -0.44156746, -0.89309501, 2.965364, 3.3427994]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model accuracy\n",
    "accuracy(X, Y, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) How low can you go?\n",
    "Do anything you want to get the best performance out of the training set. For once, let's overfit to your heart's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.12047504 -0.44156746 -0.89309501  2.965364    3.3427994 ]\n",
      "Loss: 8.662719407135402\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Weights:', weight)\n",
    "y = 1 / (1 + np.exp(-X @ weight))\n",
    "loss = -np.sum(Y * np.log(y) + (1 - Y) * np.log(1 - y))\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy(X, Y, weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
